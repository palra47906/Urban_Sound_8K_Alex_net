
---

# ğŸ§ UrbanSound8K Audio Classification using AlexNet

This repository presents a robust and CPU-compatible implementation of the **AlexNet convolutional neural network** for environmental sound classification using the [UrbanSound8K dataset](https://urbansounddataset.weebly.com/urbansound8k.html). The model is trained exclusively on **Mel-spectrogram features**, with **no audio augmentation**, making it a strong baseline for research or academic study.

---

## ğŸ“Œ Project Highlights

- ğŸ” **Dataset**: UrbanSound8K (10 sound classes)
- ğŸ§  **Model Architecture**: AlexNet (adapted for Mel-spectrogram input)
- ğŸ’» **Hardware Compatibility**: Runs efficiently on CPU (no GPU required)
- âŒ **No Audio Augmentation**: Ensures purity of learning from raw Mel features
- ğŸ“Š **Metrics Tracked**: Train, Validation, and Test Accuracy, Confusion Matrix, Classification Report

---

## ğŸ¼ Dataset Overview

**UrbanSound8K** consists of 8732 sound clips (â‰¤4 seconds) across **10 urban sound classes**:
```
air_conditioner, car_horn, children_playing, dog_bark, drilling,
engine_idling, gun_shot, jackhammer, siren, street_music
```

---

## ğŸ“ Directory Setup

Ensure your directory contains:
```
/UrbanSound8K
â”œâ”€â”€ audio/
â”‚   â”œâ”€â”€ fold1/
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ fold10/
â””â”€â”€ metadata/
    â””â”€â”€ UrbanSound8K.csv
```

Update the paths in the code:
```python
DATA_PATH = '/content/drive/MyDrive/UrbanSound8K/audio/'
METADATA_PATH = '/content/drive/MyDrive/UrbanSound8K/metadata/UrbanSound8K.csv'
```

---

## ğŸ§  AlexNet Architecture Summary

Adapted to handle `168x168x1` Mel-spectrogram inputs:

```
Input (168x168x1)
â†’ Conv2D(96, 11x11, stride=4) â†’ ReLU
â†’ MaxPooling(3x3, stride=2)
â†’ Conv2D(256, 5x5) â†’ ReLU
â†’ MaxPooling(3x3, stride=2)
â†’ Conv2D(384, 3x3) â†’ ReLU
â†’ Conv2D(384, 3x3) â†’ ReLU
â†’ Conv2D(256, 3x3) â†’ ReLU
â†’ MaxPooling(3x3, stride=2)
â†’ Flatten
â†’ Dense(4096) â†’ ReLU â†’ Dropout
â†’ Dense(4096) â†’ ReLU â†’ Dropout
â†’ Output Layer (Softmax)
```

---

## âš™ï¸ Preprocessing Workflow

1. Load metadata and audio files
2. Extract Mel-spectrograms using Librosa
3. Normalize spectrograms (Z-score)
4. Zero-pad or truncate to fixed shape (168x168)
5. One-hot encode class labels

---

## ğŸ§ª Training Configuration

| Parameter         | Value             |
|------------------|------------------|
| Epochs           | 30               |
| Batch Size       | 32               |
| Optimizer        | Adam             |
| Loss             | Categorical Crossentropy |
| Early Stopping   | Patience = 10    |

---

## ğŸ“ˆ Results

| Metric              | Value (Approx.) |
|---------------------|-----------------|
| Train Accuracy      | ~99%            |
| Validation Accuracy | ~86%            |
| Test Accuracy       | ~85%            |

---

## ğŸ”¬ Evaluation Tools

- âœ… Accuracy (Train, Validation, Test)
- ğŸ“‰ Loss curves
- ğŸ“Š Confusion Matrix
- ğŸ§¾ Classification Report (Precision, Recall, F1-score)

---

## ğŸ’» Environment Requirements

```bash
pip install numpy pandas librosa matplotlib scikit-learn tensorflow
```

---

## ğŸš€ Getting Started

1. Download and extract the [UrbanSound8K dataset](https://urbansounddataset.weebly.com/urbansound8k.html)
2. Clone this repository and open the notebook
3. Update paths for audio and metadata
4. Run all cells to train and evaluate the model

---

## ğŸ“š Citation

If you use this work in academic research, please consider citing the UrbanSound8K dataset and AlexNet architecture.

---

